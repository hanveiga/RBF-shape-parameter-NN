{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5654df-ec26-484b-943c-7cb8c82828cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import math\n",
    "from math import exp\n",
    "from random import seed\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "\n",
    "import sys\n",
    "sys.path.append('../common/')\n",
    "from utils import *\n",
    "from optimisation import *\n",
    "from loo_cv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86e483-5be7-4642-add9-8f75173ae1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c8deb-95cf-48fb-9531-6180f7df705b",
   "metadata": {},
   "source": [
    "This notebooks computes the test error, the 1d interpolatione error on 3 test cases and the 2d interpolation error in 3 test cases, both in uniform mesh and non-uniform mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309a446-b2c2-4afa-8d17-31b66dc8483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # layers, activations and more\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "from torch.jit import script, trace       # hybrid frontend decorator and tracing jit\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013178c9-b1b1-4a37-af19-afc98392be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,N=10):\n",
    "            super(Net, self).__init__()\n",
    "            \n",
    "            nInputs = int(N*N/2-N/2)\n",
    "            \n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(in_features=nInputs, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=32, out_features=16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=16, out_features=1)\n",
    "            )\n",
    "            # map to positive\n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f5cfa-054b-4a9e-8e7c-a1229c2a92b8",
   "metadata": {},
   "source": [
    "# Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2d2e9-4101-4f7e-9d5e-befd1948a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_half(A):\n",
    "    n = A.shape[0]\n",
    "    return 1/A[np.triu_indices(n, k = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2588b-1c21-43a5-b39b-77fe22587c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network to be tested:\n",
    "directory = \"plots_inter1d/\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "n=10\n",
    "path =   '../network/results_sorted_1d_2d/best_model.pt'\n",
    "model=Net()\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8336ebac-47a0-485a-84d5-18639317f6dd",
   "metadata": {},
   "source": [
    "# Interpolation one dimension with Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83338a29-1976-4be9-bd9b-03cb1af5edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_midpoints(x, iterations):\n",
    "    for itr in range(iterations):\n",
    "        # Create a new list to store midpoints\n",
    "        new_x = []\n",
    "        \n",
    "        # Iterate through the initial list and calculate midpoints\n",
    "        for i in range(len(x) - 1):\n",
    "            new_x.append(x[i])\n",
    "            midpoint = (x[i] + x[i + 1]) / 2\n",
    "            new_x.append(midpoint)\n",
    "        \n",
    "        # Add the last element of the original list\n",
    "        new_x.append(x[-1])\n",
    "        \n",
    "        # Update the original list with the new list\n",
    "        x = new_x\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1771508-73fa-44ef-bcdd-a8c8c13b95f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps_optimisation(x_axis,eps_init):\n",
    "    closs = 10.\n",
    "    total_iter = 0\n",
    "    lr_init_inside = 0.1\n",
    "    eps, closs, lr_init_inside, iters = optimization_loop_ADAM_fallback(x_axis, eps_init, lr_init_inside)\n",
    "    total_iter += iters\n",
    "            \n",
    "    return eps\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe5d3c8-3ec5-4582-8c4b-5a52b00d443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with fallback\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import math\n",
    "from math import exp\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "def one_interpolation(n,x_init,testcase,no_testcase,no_division,theta):\n",
    "    # create the points based on how many times (no_division) we want to divide the x_init\n",
    "    x_axis_total=add_midpoints(x_init, no_division)\n",
    "    replaced=0 \n",
    "    error=[0 for i in range(5)]\n",
    "    \n",
    "    A=np.zeros((n+1,n+1))     \n",
    "    right_side=np.zeros((n+1,1))    \n",
    "    w=np.zeros((n+1,1))\n",
    "    origin=np.array([0,0])\n",
    "    \n",
    "    nn_time_accum = 0\n",
    "    hardy_time_accum = 0\n",
    "    franke_time_accum = 0\n",
    "    mfranke_time_accum = 0\n",
    "    rippa_time_accum = 0\n",
    "         \n",
    "    replaced_list = []\n",
    "    for y in range(2**no_division):\n",
    "        x_axis1=np.array([x_axis_total[y*(n-1)+idx] for idx in range(n)])   \n",
    "        x_axis_rippa=x_axis1.reshape(n,1)\n",
    "        \n",
    "        x_axis=np.zeros(2*x_axis1.shape[0])\n",
    "        x_axis[::2] =x_axis1\n",
    "\n",
    "        x_axis=x_axis.reshape(n,2)\n",
    "        x_axis = sorted( x_axis, key = lambda x: np.linalg.norm(x - origin ) )#sort inputs\n",
    "        x_axis = np.reshape(x_axis, (n,2)) \n",
    "    \n",
    "        start = time.process_time()\n",
    "        X=generate_distance_from_coordinates(x_axis)\n",
    "        scaled_training_set_flat = upper_half(X).reshape((1,int(n*n/2-n/2)))\n",
    "        scaled_training_set_tensor = torch.tensor(scaled_training_set_flat,dtype=torch.float)   \n",
    "        shape_optimisation= model(scaled_training_set_tensor).item()\n",
    "        nn_time = (time.process_time() - start)\n",
    "\n",
    "        nn_time_accum += nn_time   \n",
    "        \n",
    "        \n",
    "        for count,shape in enumerate([shape_optimisation]):\n",
    "            \n",
    "            for i in range(n):\n",
    "                for j in range(n):            \n",
    "                    A[i, j] = phi(shape, x_axis_total[i+y*(n-1)], x_axis_total[j+y*(n-1)])\n",
    "            A[-1,:] =1.0\n",
    "            A[:,-1] =1.0\n",
    "            A[-1,-1]=0.0\n",
    "\n",
    "            if np.log10(np.linalg.cond(A,'fro')) > theta:#np.isinf(np.log10(np.linalg.cond(A,'fro'))):\n",
    "                # replace shape parameter\n",
    "                shape = get_eps_optimisation(x_axis,shape)\n",
    "                A = get_int_matrix(x_axis,shape)\n",
    "                #print(\"replaced\")\n",
    "                replaced+=1\n",
    "                replaced_list.append([x_axis,shape])\n",
    "            \n",
    "            else:\n",
    "                #print(\"no replace\")\n",
    "                pass\n",
    "                \n",
    "            for i in range(n):\n",
    "                right_side[i,0]=testcase(x_axis_total[i+y*(n-1)])            \n",
    "            right_side[-1,0]=0.0 \n",
    "\n",
    "            # compute the weights\n",
    "            w=np.linalg.solve(A, right_side) \n",
    "        \n",
    "            x_axis_oversampled = np.zeros((n-1,1)) \n",
    "            for p in range(n-1):\n",
    "                x_axis_oversampled[p]=(x_axis_total[p+y*(n-1)]+x_axis_total[p+1+y*(n-1)])/2.0\n",
    "\n",
    "            # compute the true values\n",
    "            true_vals=np.zeros((n-1,1))\n",
    "            for r in range(9):\n",
    "                true_vals[r,0]=testcase((x_axis_total[r+y*(n-1)]+x_axis_total[r+1+y*(n-1)])/2.0)\n",
    "\n",
    "            # compute the approximate values\n",
    "            s=np.zeros((n-1,n+1))\n",
    "            for i in range(n):      \n",
    "                for j in range(n-1):            \n",
    "                    s[j,i] = phi(shape, (x_axis_total[j+y*(n-1)]+x_axis_total[j+1+y*(n-1)])/2.0, x_axis_total[i+y*(n-1)])\n",
    "            s[:,-1]=1.0        \n",
    "            approximator_oversampled=np.matmul(s,w)\n",
    "       \n",
    "            for i in range(n-1):\n",
    "                error[count]=abs(approximator_oversampled[i,0]-true_vals[i,0])**2+error[count]\n",
    "\n",
    "        \n",
    "        \n",
    "    part_error=[math.sqrt(err/len(x_axis_total))  for err in error]\n",
    "    no_points=len(x_axis_total)\n",
    "    timings = [nn_time_accum, hardy_time_accum, franke_time_accum, mfranke_time_accum, rippa_time_accum]\n",
    "    print(f\"replaced:{replaced}\")\n",
    "            \n",
    "    return no_points,part_error,replaced,replaced_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad3b61-a2f4-486a-92ad-d2e1e8c0e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "testcase1=lambda x: np.exp(np.sin(np.pi*x))\n",
    "testcase2=lambda x: 1/(1+16*(x**2))\n",
    "testcase3=lambda x: 1.0 if x>0.5 else 0.0\n",
    "\n",
    "total_no_division=10\n",
    "no_testcase=1\n",
    "n=10\n",
    "\n",
    "for test_no,testcase in enumerate([testcase1,testcase2,testcase3]):\n",
    "    no_test=no_testcase\n",
    "    for theta in [12,16,np.inf]:\n",
    "        for uniform in ['false']:\n",
    "            x_vec=[]\n",
    "            optimisation_error=[]\n",
    "            hardy_error=[]\n",
    "            franke_error=[]\n",
    "            mfranke_error=[]\n",
    "            rippa_error=[]\n",
    "\n",
    "            if uniform=='true':\n",
    "                x_init=[0,1/9,2/9,3/9,4/9,5/9,6/9,7/9,8/9,1]\n",
    "            elif uniform =='false':\n",
    "                x_init=[0.5+0.5*np.cos((2*k-1)*np.pi/20.0) for k in range(1,11)]\n",
    "            x_init.sort()\n",
    "\n",
    "            for no_division in range(total_no_division):\n",
    "                        no_points,part_error,nreplaced,replaced_list=one_interpolation(n,x_init,testcase,no_testcase,no_division,theta)\n",
    "                        x_vec.append(no_points)\n",
    "                        optimisation_error.append(part_error[0])\n",
    "                        with open(f'test_{test_no}_{theta}_{uniform}.csv','a') as csvfile:\n",
    "                            csvfile.write(f\"{no_points},{part_error[0]},{nreplaced} \\n\")\n",
    "                        pickle.dump(replaced_list,open(f'test_{test_no}_{theta}_{uniform}_{no_division}_list_of_points.pkl','wb'))\n",
    "\n",
    "\n",
    "            #print(optimisation_error)\n",
    "\n",
    "            fig=plt.figure()\n",
    "\n",
    "            plt.loglog(x_vec,optimisation_error,color='r',marker='o')\n",
    "\n",
    "\n",
    "            plt.xlabel('N',fontsize=12)\n",
    "            plt.ylabel('Error',fontsize=12)\n",
    "            plt.savefig(directory+'testcase_fall_'+str(theta)+str(no_testcase)+uniform+'.png')  \n",
    "            plt.close()\n",
    "        no_testcase+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7501d1-88f2-4442-9c76-8b25c5524272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RBF",
   "language": "python",
   "name": "rbf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
