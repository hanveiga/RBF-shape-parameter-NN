{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd5654df-ec26-484b-943c-7cb8c82828cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import math\n",
    "from math import exp\n",
    "from random import seed\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "from scipy.ndimage import map_coordinates\n",
    "from skimage.transform import resize\n",
    "\n",
    "import sys\n",
    "sys.path.append('../common/')\n",
    "\n",
    "from image_commons import *\n",
    "from utils import *\n",
    "from optimisation import *\n",
    "from loo_cv import *\n",
    "from rbf_tools import *\n",
    "from two_dim import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c86e483-5be7-4642-add9-8f75173ae1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1461341d33f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed=0\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c8deb-95cf-48fb-9531-6180f7df705b",
   "metadata": {},
   "source": [
    "This notebooks computes the test error, the 1d interpolatione error on 3 test cases and the 2d interpolation error in 3 test cases, both in uniform mesh and non-uniform mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c309a446-b2c2-4afa-8d17-31b66dc8483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # layers, activations and more\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "from torch.jit import script, trace       # hybrid frontend decorator and tracing jit\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "013178c9-b1b1-4a37-af19-afc98392be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,N=10):\n",
    "            super(Net, self).__init__()\n",
    "            \n",
    "            nInputs = int(N*N/2-N/2)\n",
    "            \n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(in_features=nInputs, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=32, out_features=16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=16, out_features=1)\n",
    "            )\n",
    "            # map to positive\n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f5cfa-054b-4a9e-8e7c-a1229c2a92b8",
   "metadata": {},
   "source": [
    "# generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aea2d2e9-4101-4f7e-9d5e-befd1948a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_half(A):\n",
    "    n = A.shape[0]\n",
    "    return 1/A[np.triu_indices(n, k = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05a2588b-1c21-43a5-b39b-77fe22587c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=45, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network to be tested:\n",
    "directory = \"plots/\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# network to be tested:\n",
    "n=10\n",
    "path =   '../network/results_sorted_1d_2d/best_model.pt'\n",
    "model=Net()\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e588d9d-95b5-49d7-adba-ecdefa550fb8",
   "metadata": {},
   "source": [
    "# Upscale two dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee10e6e2-e50c-4c42-a9e2-7ad47f782dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_image(image, downscaled_image):\n",
    "    original_shape = image.shape\n",
    "\n",
    "    # Prepare data for RBF interpolation\n",
    "    # interpolation points\n",
    "    x = np.linspace(0, original_shape[0] - 1, downscaled_image.shape[0])\n",
    "    y = np.linspace(0, original_shape[1] - 1, downscaled_image.shape[1])\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    coords = np.vstack([xv.ravel(), yv.ravel()]).T  # Create a list of coordinates\n",
    "    \n",
    "    values = downscaled_image.ravel()  # Flatten grayscale values\n",
    "\n",
    "    #evaluation points\n",
    "    x_full = np.linspace(0, original_shape[0] - 1, original_shape[0])\n",
    "    y_full = np.linspace(0, original_shape[1] - 1, original_shape[1])\n",
    "    xv_full, yv_full = np.meshgrid(x_full, y_full)\n",
    "    coords_full = np.vstack([xv_full.ravel(), yv_full.ravel()]).T\n",
    "\n",
    "    p_ref=np.array([0,0])    \n",
    "    no_evaluation_points=coords_full.shape[0]\n",
    "    distance =cdist(coords_full,coords)\n",
    "    closest = np.argpartition(distance, 10, axis=1)\n",
    "    scaled_training_set_flat = []\n",
    "    eps_final_hardy=np.zeros((no_evaluation_points,1))\n",
    "    eps_final_franke=np.zeros((no_evaluation_points,1))\n",
    "    eps_final_mfranke=np.zeros((no_evaluation_points,1))\n",
    "    eps_final_rippa=np.zeros((no_evaluation_points,1))\n",
    "    eps_final_mle=np.zeros((no_evaluation_points,1))\n",
    "    \n",
    "    x_coords = []\n",
    "    f=[]\n",
    "    upscaled_flat=np.zeros((6,no_evaluation_points))\n",
    "    print(no_evaluation_points)\n",
    "    for i in range(no_evaluation_points):\n",
    "        x_local=np.zeros((10,2))\n",
    "        fpart=np.zeros((10+1,1))\n",
    "        for j in range(10):\n",
    "            x_local[j]=coords[closest[i][j]]\n",
    "            fpart[j]=values[closest[i][j]]\n",
    "        x_local = sorted( x_local, key = lambda x: np.linalg.norm(x - p_ref ) )\n",
    "        x_local = np.reshape(x_local, (10,2)) \n",
    "        x_coords.append(x_local)\n",
    "        f.append(fpart)\n",
    "        x_axis=x_local.reshape(10,2)\n",
    "        # Hardy approach\n",
    "        nearest_distances = find_nearest_neighbors(x_axis)\n",
    "        d=np.sum(nearest_distances)/n        \n",
    "        eps_final_hardy[i]=1/(0.815*d)\n",
    "\n",
    "        # Franke approach\n",
    "        x_axis_list=x_axis.tolist()        \n",
    "        circle = find_min_circle(x_axis_list)\n",
    "        eps_final_franke[i]=0.8*(10**(1/2))/(2 * circle[2])\n",
    "\n",
    "        # Modified Franke approach\n",
    "        eps_final_mfranke[i]=0.8*(10**(1/4))/(2 * circle[2])\n",
    "\n",
    "        # Rippa approach       \n",
    "        rhs_rippa = fpart[:10]\n",
    "        eps_v = [0.001, 0.002, 0.005, 0.0075, 0.01, 0.02, 0.05, \\\n",
    "                 0.075, 0.1, 0.2, 0.5, 0.75,1,2, 5, 7.5, 10, 20.0, 50, 75, 100, 200, 500, 1000]\n",
    "        #\n",
    "        best_eps = 0\n",
    "        old_error = np.inf        \n",
    "        for eps in eps_v:\n",
    "            error_r = rippa_cv(eps, x_axis, rhs_rippa)\n",
    "            if error_r < old_error:\n",
    "               best_eps = eps\n",
    "               old_error = error_r\n",
    "        eps_final_rippa[i]=best_eps\n",
    "\n",
    "        ## MLE approach\n",
    "        rhs_rippa = fpart[:10]\n",
    "        #eps_v = #np.concatenate([np.linspace(0.001,30,200),[50.0, 75.0, 100.0, 200.0, 500.0, 1000.0]]) \n",
    "        best_eps = 1.0\n",
    "        old_error = np.inf        \n",
    "        for eps in eps_v:\n",
    "            error_r = mle_cv(eps, x_axis, rhs_rippa)\n",
    "            if error_r < old_error:\n",
    "               best_eps = eps\n",
    "               old_error = error_r\n",
    "        eps_final_mle[i]=best_eps\n",
    "        #print(best_eps)\n",
    "        \n",
    "        # NN approach\n",
    "        xxx=generate_distance_from_coordinates(x_axis)               \n",
    "        training_set_distances_flatten = upper_half(xxx)\n",
    "        scaled_training_set_flat.append(training_set_distances_flatten)\n",
    "        if i%1000==0:\n",
    "            print(i)\n",
    "\n",
    "    \n",
    "    scaled_training_set_tensor = torch.tensor(scaled_training_set_flat,dtype=torch.float)\n",
    "    scaled_training_set_tensor.reshape((no_evaluation_points,int(10*10/2-10/2)))\n",
    "        \n",
    "    eps_final= model(scaled_training_set_tensor)\n",
    "    eps_final_optimisation = eps_final.detach().numpy()\n",
    "    print(eps_final_optimisation)\n",
    "    for j in range(no_evaluation_points):\n",
    "        for count,eps in enumerate([eps_final_mle[j][0],eps_final_rippa[j][0],eps_final_hardy[j][0],eps_final_franke[j][0],eps_final_mfranke[j][0],eps_final_optimisation[j][0]]):\n",
    "            L =  get_int_matrix(x_coords[j],eps)                \n",
    "            fx=f[j]\n",
    "           \n",
    "            w=np.linalg.solve(L, fx)             \n",
    "            \n",
    "            s=np.zeros((1,10+1))\n",
    "            for i in range(10):      \n",
    "                s[0,i] = phi(eps,coords_full[j] , x_coords[j][i])\n",
    "            s[0,-1]=1.0        \n",
    "            \n",
    "            upscaled_flat[count][j]=np.matmul(s,w)          \n",
    "        \n",
    "    upscaled_image=[]\n",
    "    for count in range(6):        \n",
    "        upscaled_image.append(upscaled_flat[count].reshape(original_shape[:2]))\n",
    "    return upscaled_image\n",
    "\n",
    "# Visualize the images\n",
    "def display_images(upscaled_image,file_name):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(upscaled_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'upscaled_'+file_name,bbox_inches='tight', dpi=150)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677a3364-ab8d-4fec-9eff-e88edd4e0cfb",
   "metadata": {},
   "source": [
    "# Checkerboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb0464d-a6d2-41b2-baac-dc2e240c1d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PAS2708/hanveiga1/new_rbf/RBF-shape-parameter-NN/2-dimensional/../common/loo_cv.py:51: RuntimeWarning: invalid value encountered in log\n",
      "  term2 = np.log(np.linalg.det(M)+1e-16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "image = create_checkerboard(size=(200, 200), num_checks=10)  # Create a synthetic checkerboard image\n",
    "original_shape = image.shape\n",
    "\n",
    "downscale_factor = 0.5\n",
    "downscaled_image = resize(image, (int(original_shape[0] * downscale_factor),\n",
    "                                  int(original_shape[1] * downscale_factor)))\n",
    "\n",
    "upscaled_image = upscale_image(image, downscaled_image)  # upscale the image\n",
    "\n",
    "fig1 = plt.figure(figsize=(10, 6))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'original',bbox_inches='tight', dpi=150)\n",
    "plt.close(fig1)\n",
    "\n",
    "fig2 = plt.figure(figsize=(5, 3))\n",
    "plt.imshow(downscaled_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'downscaled',bbox_inches='tight', dpi=150)\n",
    "plt.close(fig2)\n",
    "\n",
    "strategies=['MLE','Rippa','Hardy','Franke','Modified Franke', 'NN']\n",
    "\n",
    "mse=[0 for i in range(6)]\n",
    "psnr=[0 for i in range(6)]\n",
    "\n",
    "for count in range(6):\n",
    "    display_images(upscaled_image[count],f\"{strategies[count]}_upscale_checkerboard\")  # Display the images\n",
    "    mse[count] = np.mean((image - upscaled_image[count]) ** 2)\n",
    "    psnr[count]=20*np.log10(np.max(image)/np.sqrt(mse[count]))\n",
    "\n",
    "print('mse',mse)\n",
    "print('psnr',psnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b17d7d2-6dbd-41e2-92cf-1485b56ec18d",
   "metadata": {},
   "source": [
    "# Pepper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d0b83c-cb23-4103-b574-b79fefb0930d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PAS2708/hanveiga1/RBF-shape-parameter-NN/2-dimensional/image/../../common/loo_cv.py:51: RuntimeWarning: invalid value encountered in log\n",
      "  term2 = np.log(np.linalg.det(M)+1e-16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.672334/ipykernel_3483287/4005633290.py:98: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995026/work/torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  scaled_training_set_tensor = torch.tensor(scaled_training_set_flat,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.2928782]\n",
      " [2.2983208]\n",
      " [2.2927067]\n",
      " ...\n",
      " [2.2914257]\n",
      " [2.2910979]\n",
      " [2.2931643]]\n",
      "mse [0.007672205671218552, 0.007670825120523483, 0.007472746263846776, 0.007861158756381164, 0.007854443495780206, 0.005167534164862738]\n",
      "psnr [20.909027641977683, 20.90980918971569, 21.02342764692147, 20.803364338277103, 20.807075810168843, 22.625396441620587]\n"
     ]
    }
   ],
   "source": [
    "path = 'flower.png'\n",
    "image = load_image(path) \n",
    "original_shape = image.shape\n",
    "\n",
    "downscale_factor = 0.5\n",
    "downscaled_image = resize(image, (int(original_shape[0] * downscale_factor),\n",
    "                                  int(original_shape[1] * downscale_factor)))\n",
    "\n",
    "upscaled_image = upscale_image(image, downscaled_image)  # upscale the image\n",
    "\n",
    "fig1 = plt.figure(figsize=(10, 6))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'original_flower',bbox_inches='tight', dpi=150)\n",
    "plt.close(fig1)\n",
    "\n",
    "fig2 = plt.figure(figsize=(5, 3))\n",
    "plt.imshow(downscaled_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'downscaled_flower',bbox_inches='tight', dpi=150)\n",
    "plt.close(fig2)\n",
    "\n",
    "strategies=['MLE','Rippa','Hardy','Franke','Modified Franke', 'NN']\n",
    "\n",
    "mse=[0 for i in range(6)]\n",
    "psnr=[0 for i in range(6)]\n",
    "\n",
    "for count in range(6):\n",
    "    display_images(upscaled_image[count],strategies[count]+'_upscale_flower')  # Display the images\n",
    "    mse[count] = np.mean((image - upscaled_image[count]) ** 2)\n",
    "    psnr[count]=20*np.log10(np.max(image)/np.sqrt(mse[count]))\n",
    "\n",
    "print('mse',mse)\n",
    "print('psnr',psnr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RBF",
   "language": "python",
   "name": "rbf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
