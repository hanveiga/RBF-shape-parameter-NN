{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5654df-ec26-484b-943c-7cb8c82828cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import math\n",
    "from math import exp\n",
    "from random import seed\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "\n",
    "import sys\n",
    "sys.path.append('../common/')\n",
    "from utils import *\n",
    "from optimisation import *\n",
    "from loo_cv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c86e483-5be7-4642-add9-8f75173ae1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b58cdd670d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed=0\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c8deb-95cf-48fb-9531-6180f7df705b",
   "metadata": {},
   "source": [
    "This notebooks computes the test error, the 1d interpolatione error on 3 test cases and the 2d interpolation error in 3 test cases, both in uniform mesh and non-uniform mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c309a446-b2c2-4afa-8d17-31b66dc8483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # layers, activations and more\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "from torch.jit import script, trace       # hybrid frontend decorator and tracing jit\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013178c9-b1b1-4a37-af19-afc98392be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,N=10):\n",
    "            super(Net, self).__init__()\n",
    "            \n",
    "            nInputs = int(N*N/2-N/2)\n",
    "            \n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(in_features=nInputs, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=32, out_features=16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=16, out_features=1)\n",
    "            )\n",
    "            # map to positive\n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f5cfa-054b-4a9e-8e7c-a1229c2a92b8",
   "metadata": {},
   "source": [
    "# generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea2d2e9-4101-4f7e-9d5e-befd1948a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_half(A):\n",
    "    n = A.shape[0]\n",
    "    return 1/A[np.triu_indices(n, k = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05a2588b-1c21-43a5-b39b-77fe22587c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=45, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network to be tested:\n",
    "directory = \"plots/\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "n=10\n",
    "path =   '../network/results_sorted_1d_2d/best_model.pt'\n",
    "model=Net()\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e588d9d-95b5-49d7-adba-ecdefa550fb8",
   "metadata": {},
   "source": [
    "# checking condition number on test/train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eec8332c-908c-4ed7-87b9-37d63ff83152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolation two dimension uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0524dcce-ff7f-40ba-99e1-74d0ab1dd68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new interpolation two dimension \n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import math\n",
    "from math import exp\n",
    "from random import seed\n",
    "\n",
    "from scipy.spatial import distance\n",
    "import pickle\n",
    "from rbf_tools import *\n",
    "from two_dim import *\n",
    "\n",
    "def phi(f, x, y):\n",
    "    z = (1 + (f * np.linalg.norm(x-y)) ** 2) ** (-0.5)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2960c46a-b45d-4dfb-87ab-a8fb5689e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def euclidean_distance(p1, p2):\n",
    "    return np.sqrt(np.sum((p1 - p2) ** 2))\n",
    "\n",
    "def find_nearest_neighbors2(points):\n",
    "    num_points = points.shape[0]\n",
    "    distances = np.full(num_points, np.inf)\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        for j in range(num_points):\n",
    "            if i != j:\n",
    "                distance = euclidean_distance(points[i], points[j])\n",
    "                if distance < distances[i]:\n",
    "                    distances[i] = distance\n",
    "    \n",
    "    return distances\n",
    "\n",
    "\n",
    "def find_nearest_neighbors(points):\n",
    "    num_points = points.shape[0]\n",
    "    \n",
    "    distance_matrix =cdist(points,points) \n",
    "    np.fill_diagonal(distance_matrix,np.inf)\n",
    "    \n",
    "    distances = np.zeros(num_points)\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        distances[i] = np.min(distance_matrix[i,:])\n",
    "        \n",
    "    return distances\n",
    "\n",
    "# Function to compute the Euclidean distance between two points\n",
    "def dist(p1, p2):\n",
    "    return math.hypot(p1[0] - p2[0], p1[1] - p2[1])\n",
    "\n",
    "# Function to check if a point is inside a circle\n",
    "def is_inside_circle(p, c):\n",
    "    return dist(p, c[:2]) <= c[2]\n",
    "\n",
    "# Function to compute the circle from 3 points\n",
    "def circle_from_3_points(p1, p2, p3):\n",
    "    A = p2[0] - p1[0]\n",
    "    B = p2[1] - p1[1]\n",
    "    C = p3[0] - p1[0]\n",
    "    D = p3[1] - p1[1]\n",
    "    E = A * (p1[0] + p2[0]) + B * (p1[1] + p2[1])\n",
    "    F = C * (p1[0] + p3[0]) + D * (p1[1] + p3[1])\n",
    "    G = 2 * (A * (p3[1] - p2[1]) - B * (p3[0] - p2[0]))\n",
    "    \n",
    "    if G == 0:  # Collinear points\n",
    "        return None\n",
    "    \n",
    "    cx = (D * E - B * F) / G\n",
    "    cy = (A * F - C * E) / G\n",
    "    r = dist((cx, cy), p1)\n",
    "    \n",
    "    return (cx, cy, r)\n",
    "\n",
    "# Function to compute the circle from 2 points\n",
    "def circle_from_2_points(p1, p2):\n",
    "    cx = (p1[0] + p2[0]) / 2\n",
    "    cy = (p1[1] + p2[1]) / 2\n",
    "    r = dist(p1, p2) / 2\n",
    "    return (cx, cy, r)\n",
    "\n",
    "# Recursive function to find the minimum enclosing circle\n",
    "def welzl(P, R, n):\n",
    "    if n == 0 or len(R) == 3:\n",
    "        if len(R) == 0:\n",
    "            return (0, 0, 0)\n",
    "        elif len(R) == 1:\n",
    "            return (R[0][0], R[0][1], 0)\n",
    "        elif len(R) == 2:\n",
    "            return circle_from_2_points(R[0], R[1])\n",
    "        else:\n",
    "            return circle_from_3_points(R[0], R[1], R[2])\n",
    "    \n",
    "    idx = rand.randint(0, n - 1)\n",
    "    p = P[idx]\n",
    "    P[idx], P[n - 1] = P[n - 1], P[idx]\n",
    "    \n",
    "    d = welzl(P, R, n - 1)\n",
    "    \n",
    "    if is_inside_circle(p, d):\n",
    "        return d\n",
    "    \n",
    "    return welzl(P, R + [p], n - 1)\n",
    "\n",
    "# Function to find the minimum enclosing circle\n",
    "def find_min_circle(points):\n",
    "    P = points[:]\n",
    "    #random.shuffle(P)\n",
    "    return welzl(P, [], len(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98256717-8626-421e-867c-3cb56cd04127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "\n",
    "def two_interpolation(model,testcase,no_testcase,N,oversampling,a,b,c,d,n):\n",
    "    \n",
    "    p_ref=np.array([0,0])       \n",
    "    x=get_structured_points_modified(a,b,c,d,N)\n",
    "    evall=get_structured_points_modified(a,b,c,d,oversampling*N)\n",
    "    no_interpolation_points= x.shape[0]\n",
    "    no_evaluation_points= evall.shape[0]\n",
    "     \n",
    "    distance =cdist(evall,x)\n",
    "\n",
    "    closest = np.argpartition(distance, 10, axis=1)\n",
    "    scaled_training_set_flat = []\n",
    "    x_coords = []\n",
    "    \n",
    "    eps_final_hardy=np.zeros((no_evaluation_points,1))\n",
    "    eps_final_franke=np.zeros((no_evaluation_points,1))\n",
    "    eps_final_mfranke=np.zeros((no_evaluation_points,1))\n",
    "    eps_final_rippa=np.zeros((no_evaluation_points,1))\n",
    "\n",
    "    nn_time_accum = 0\n",
    "    hardy_time_accum = 0\n",
    "    franke_time_accum = 0\n",
    "    mfranke_time_accum = 0\n",
    "    rippa_time_accum = 0\n",
    "    \n",
    "    # generate features\n",
    "    for i in range(no_evaluation_points):\n",
    "        x_local=np.zeros((n,2))\n",
    "        for j in range(n):\n",
    "            x_local[j]=x[closest[i][j]]\n",
    "\n",
    "        x_local = sorted( x_local, key = lambda x: np.linalg.norm(x - p_ref ) )#change for sorted inputs\n",
    "        x_local = np.reshape(x_local, (10,2)) \n",
    "        x_coords.append(x_local)\n",
    "        x_axis=x_local.reshape(10,2)\n",
    "        #x_axis = sorted( x_axis, key = lambda x: np.linalg.norm(x - p_ref ) )#change for sorted inputs\n",
    "        #x_axis = np.reshape(x_axis, (10,2)) \n",
    "\n",
    "        start = time.process_time()\n",
    "        nearest_distances = find_nearest_neighbors(x_axis)\n",
    "        d=np.sum(nearest_distances)/n        \n",
    "        eps_final_hardy[i]=1/(0.815*d)\n",
    "        hardy_time = (time.process_time() - start) \n",
    "        hardy_time_accum += hardy_time\n",
    "\n",
    "        \n",
    "        start = time.process_time()  \n",
    "        x_axis_list=x_axis.tolist()\n",
    "        circle = find_min_circle(x_axis_list)\n",
    "        d_time = (time.process_time() - start)\n",
    "\n",
    "        start = time.process_time()\n",
    "        eps_final_franke[i]=0.8*(10**(1/2))/(2 * circle[2])\n",
    "        franke_time = (time.process_time() - start) + d_time\n",
    "        franke_time_accum += franke_time\n",
    "\n",
    "        start = time.process_time()\n",
    "        eps_final_mfranke[i]=0.8*(10**(1/4))/(2 * circle[2])\n",
    "        mfranke_time = (time.process_time() - start) + d_time\n",
    "        mfranke_time_accum += mfranke_time\n",
    "\n",
    "        start = time.process_time()\n",
    "        #compute shape parameter from Rippa approach       \n",
    "        rhs_rippa = np.array([testcase(x[0],x[1]) for x in x_axis])\n",
    "        #eps_v = np.linspace(0.001,200,600)\n",
    "        #eps_v = np.linspace(0.001,1000,24)\n",
    "        eps_v = [0.001, 0.002, 0.005, 0.0075, 0.01, 0.02, 0.05, 0.075, 0.1, 0.2, 0.5, 0.75, 1.0,\\\n",
    "                 2.0, 5.0, 7.5, 10.0, 20.0, 50.0, 75.0, 100.0, 200.0, 500.0, 1000.0] # from python library\n",
    "\n",
    "        best_eps = 0\n",
    "        old_error = np.inf\n",
    "        \n",
    "        for eps in eps_v:\n",
    "            error_r = rippa_cv(eps, x_axis, rhs_rippa)\n",
    "            if error_r < old_error:\n",
    "               best_eps = eps\n",
    "               old_error = error_r\n",
    "        eps_final_rippa[i]=best_eps\n",
    "        rippa_time = (time.process_time() - start)\n",
    "        rippa_time_accum+=rippa_time\n",
    "\n",
    "        start = time.process_time()\n",
    "        xxx=generate_distance_from_coordinates(x_axis)               \n",
    "        training_set_distances_flatten = upper_half(xxx)\n",
    "        scaled_training_set_flat.append(training_set_distances_flatten)\n",
    "        nn_time_accum += (time.process_time() - start)\n",
    "\n",
    "    start = time.process_time()\n",
    "    scaled_training_set_flat = np.array(scaled_training_set_flat)\n",
    "    scaled_training_set_tensor = torch.tensor(scaled_training_set_flat,dtype=torch.float)\n",
    "    scaled_training_set_tensor.reshape((no_evaluation_points,int(n*n/2-n/2)))\n",
    "    \n",
    "    \n",
    "    eps_final= model(scaled_training_set_tensor)\n",
    "    eps_final_optimisation = eps_final.detach().numpy()\n",
    "    nn_time_accum += (time.process_time() - start)\n",
    "\n",
    "    error2=[0 for i in range(5)]\n",
    "    \n",
    "    for j in range(no_evaluation_points):\n",
    "        for count,eps in enumerate([eps_final_rippa[j][0],eps_final_hardy[j][0],eps_final_franke[j][0],eps_final_mfranke[j][0],eps_final_optimisation[j][0]]):\n",
    "        \n",
    "            L =  get_int_matrix(x_coords[j],eps)\n",
    "            cond = np.linalg.cond(L,'fro')\n",
    "            final_error=compute_evaluation_error(x_coords[j],evall[j],testcase,phi,L,eps,n)\n",
    "            error2[count]=error2[count]+final_error\n",
    "        \n",
    "    final_tot_error = [math.sqrt(err/no_evaluation_points) for err in error2]\n",
    "    timings = [nn_time_accum, hardy_time_accum, franke_time_accum, mfranke_time_accum, rippa_time_accum]\n",
    "    return final_tot_error, timings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f12ddf7-b7e3-47be-9bec-328698d2b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "nunsuccessful = 0\n",
    "oversampling=2\n",
    "a,c=0.0,0.0\n",
    "b,d=1.0,1.0        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb8bb6-0bd4-4eb5-88c5-181e7e9b4b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PAS2708/hanveiga1/RBF-shape-parameter-NN/2-dimensional/../common/loo_cv.py:17: RuntimeWarning: divide by zero encountered in divide\n",
      "  error_vector = np.divide(w,np.diagonal(invM))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 & 1.4e-01 & 1.7e-01 & 1.7e-01                & 1.6e+01 & 6.9e-01  \\\\ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PAS2708/hanveiga1/RBF-shape-parameter-NN/2-dimensional/../common/loo_cv.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  error_vector = np.divide(w,np.diagonal(invM))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 & 5.4e-01 & 6.6e-01 & 6.5e-01                & 6.2e+01 & 2.6e+00  \\\\ \n"
     ]
    }
   ],
   "source": [
    "n=10 # length of stencil\n",
    "testcase1=lambda x,y,alpha=0.1: (1+np.exp(-1.0/alpha)-np.exp(-x/alpha)-np.exp((x-1.0)/alpha))*(1+np.exp(-1.0/alpha)-np.exp(-y/alpha)-np.exp((y-1.0)/alpha))\n",
    "testcase2=lambda x,y,alpha=1.0: (1+np.exp(-1.0/alpha)-np.exp(-x/alpha)-np.exp((x-1.0)/alpha))*(1+np.exp(-1.0/alpha)-np.exp(-y/alpha)-np.exp((y-1.0)/alpha))\n",
    "testcase3=lambda x,y: 0.75*np.exp(-(9.0*x-2.0)**2/4.0-(9.0*y-2.0)**2/4.0)+0.75*np.exp(-(9.0*x+1.0)**2/49.0-(9.0*y+1.0)**2/10.0)+0.5*np.exp(-(9.0*x-7.0)**2/4.0-(9.0*y-3.0)**2/4.0)-0.2*np.exp(-(9.0*x-4.0)**2-(9.0*y-7.0)**2)\n",
    "\n",
    "no_testcase=1\n",
    "nx=[20,40,60,80,100,120]\n",
    "\n",
    "for testcase in [testcase1,testcase2,testcase3]:\n",
    "    no_test=no_testcase\n",
    "    x_vec=[]\n",
    "\n",
    "    error_rippa=[]\n",
    "    error_hardy=[]\n",
    "    error_franke=[]\n",
    "    error_mfranke=[]\n",
    "    error_optimisation=[]\n",
    "    \n",
    "    for N in nx:\n",
    "        final_error, timings=two_interpolation(model,testcase,no_testcase,N,oversampling,a,b,c,d,n)\n",
    "        x_vec.append(N*N*oversampling*oversampling)\n",
    "        error_rippa.append(final_error[0])\n",
    "        error_hardy.append(final_error[1])\n",
    "        error_franke.append(final_error[2])\n",
    "        error_mfranke.append(final_error[3])\n",
    "        error_optimisation.append(final_error[4])\n",
    "\n",
    "        # Elements & Hardy & Frake & Modified Franke & Rippa & NN\\\\ [0.5ex] \n",
    "        print(f\"{N} & {timings[1]:.1e} & {timings[2]:.1e} & {timings[3]:.1e}\\\n",
    "                & {timings[4]:.1e} & {timings[0]:.1e}  \\\\\\\\ \")\n",
    "    print(error_rippa)\n",
    "    print(error_hardy)\n",
    "    print(error_franke)\n",
    "    print(error_mfranke)\n",
    "    print(error_optimisation)\n",
    "    print('********')\n",
    "    fig=plt.figure()\n",
    "    plt.loglog(x_vec,error_rippa,color='b',marker='o')\n",
    "    plt.loglog(x_vec,error_hardy,color='orange',marker='o')\n",
    "    plt.loglog(x_vec,error_franke,color='g',marker='o')\n",
    "    plt.loglog(x_vec,error_mfranke,color='purple',marker='o')\n",
    "    plt.loglog(x_vec,error_optimisation,color='r',marker='o')\n",
    "    \n",
    "    plt.ylabel('Error', fontsize=\"12\")\n",
    "    plt.xlabel('# Evaluation points', fontsize=\"12\")\n",
    "    plt.legend([\"Rippa\",\"Hardy\",\"Franke\",\"Modified Franke\",\"NN\"],fontsize=\"12\",  loc =\"best\")\n",
    "    plt.savefig(directory+'testcase'+str(no_testcase)+'.png')  \n",
    "    plt.close()\n",
    "    \n",
    "    no_testcase+=1   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RBF",
   "language": "python",
   "name": "rbf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
