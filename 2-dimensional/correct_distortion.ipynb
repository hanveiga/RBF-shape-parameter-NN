{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5654df-ec26-484b-943c-7cb8c82828cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import math\n",
    "from math import exp\n",
    "from random import seed\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "\n",
    "import sys\n",
    "sys.path.append('../common/')\n",
    "from utils import *\n",
    "from optimisation import *\n",
    "from loo_cv import *\n",
    "from rbf_tools import *\n",
    "from two_dim import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c86e483-5be7-4642-add9-8f75173ae1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1160ff210>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed=0\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64c8deb-95cf-48fb-9531-6180f7df705b",
   "metadata": {},
   "source": [
    "This notebooks computes the test error, the 1d interpolatione error on 3 test cases and the 2d interpolation error in 3 test cases, both in uniform mesh and non-uniform mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c309a446-b2c2-4afa-8d17-31b66dc8483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # layers, activations and more\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "from torch.jit import script, trace       # hybrid frontend decorator and tracing jit\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013178c9-b1b1-4a37-af19-afc98392be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,N=10):\n",
    "            super(Net, self).__init__()\n",
    "            \n",
    "            nInputs = int(N*N/2-N/2)\n",
    "            \n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(in_features=nInputs, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=32, out_features=16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=16, out_features=1)\n",
    "            )\n",
    "            # map to positive\n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f5cfa-054b-4a9e-8e7c-a1229c2a92b8",
   "metadata": {},
   "source": [
    "# generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea2d2e9-4101-4f7e-9d5e-befd1948a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_half(A):\n",
    "    n = A.shape[0]\n",
    "    return 1/A[np.triu_indices(n, k = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05a2588b-1c21-43a5-b39b-77fe22587c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=45, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network to be tested:\n",
    "n=10\n",
    "path =   '../network/results_sorted_1d_2d/best_model.pt'\n",
    "model=Net()\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e588d9d-95b5-49d7-adba-ecdefa550fb8",
   "metadata": {},
   "source": [
    "# interpolation two dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0524dcce-ff7f-40ba-99e1-74d0ab1dd68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import math\n",
    "from math import exp\n",
    "from random import seed\n",
    "from scipy.spatial import distance\n",
    "import pickle\n",
    "\n",
    "\n",
    "def phi(f, x, y):\n",
    "    z = (1 + (f * np.linalg.norm(x-y)) ** 2) ** (-0.5)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2960c46a-b45d-4dfb-87ab-a8fb5689e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(p1, p2):\n",
    "    return np.sqrt(np.sum((p1 - p2) ** 2))\n",
    "\n",
    "def find_nearest_neighbors(points):\n",
    "    num_points = points.shape[0]\n",
    "    distances = np.full(num_points, np.inf)\n",
    "    \n",
    "    for i in range(num_points):\n",
    "        for j in range(num_points):\n",
    "            if i != j:\n",
    "                distance = euclidean_distance(points[i], points[j])\n",
    "                if distance < distances[i]:\n",
    "                    distances[i] = distance\n",
    "    \n",
    "    return distances\n",
    "# Function to compute the Euclidean distance between two points\n",
    "def dist(p1, p2):\n",
    "    return math.hypot(p1[0] - p2[0], p1[1] - p2[1])\n",
    "\n",
    "# Function to check if a point is inside a circle\n",
    "def is_inside_circle(p, c):\n",
    "    return dist(p, c[:2]) <= c[2]\n",
    "\n",
    "# Function to compute the circle from 3 points\n",
    "def circle_from_3_points(p1, p2, p3):\n",
    "    A = p2[0] - p1[0]\n",
    "    B = p2[1] - p1[1]\n",
    "    C = p3[0] - p1[0]\n",
    "    D = p3[1] - p1[1]\n",
    "    E = A * (p1[0] + p2[0]) + B * (p1[1] + p2[1])\n",
    "    F = C * (p1[0] + p3[0]) + D * (p1[1] + p3[1])\n",
    "    G = 2 * (A * (p3[1] - p2[1]) - B * (p3[0] - p2[0]))\n",
    "    \n",
    "    if G == 0:  # Collinear points\n",
    "        return None\n",
    "    \n",
    "    cx = (D * E - B * F) / G\n",
    "    cy = (A * F - C * E) / G\n",
    "    r = dist((cx, cy), p1)\n",
    "    \n",
    "    return (cx, cy, r)\n",
    "\n",
    "# Function to compute the circle from 2 points\n",
    "def circle_from_2_points(p1, p2):\n",
    "    cx = (p1[0] + p2[0]) / 2\n",
    "    cy = (p1[1] + p2[1]) / 2\n",
    "    r = dist(p1, p2) / 2\n",
    "    return (cx, cy, r)\n",
    "\n",
    "# Recursive function to find the minimum enclosing circle\n",
    "def welzl(P, R, n):\n",
    "    if n == 0 or len(R) == 3:\n",
    "        if len(R) == 0:\n",
    "            return (0, 0, 0)\n",
    "        elif len(R) == 1:\n",
    "            return (R[0][0], R[0][1], 0)\n",
    "        elif len(R) == 2:\n",
    "            return circle_from_2_points(R[0], R[1])\n",
    "        else:\n",
    "            return circle_from_3_points(R[0], R[1], R[2])\n",
    "    \n",
    "    idx = rand.randint(0, n - 1)\n",
    "    p = P[idx]\n",
    "    P[idx], P[n - 1] = P[n - 1], P[idx]\n",
    "    \n",
    "    d = welzl(P, R, n - 1)\n",
    "    \n",
    "    if is_inside_circle(p, d):\n",
    "        return d\n",
    "    \n",
    "    return welzl(P, R + [p], n - 1)\n",
    "\n",
    "# Function to find the minimum enclosing circle\n",
    "def find_min_circle(points):\n",
    "    P = points[:]\n",
    "    #random.shuffle(P)\n",
    "    return welzl(P, [], len(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c309e6e-d10a-40d0-a5e6-1c219f7845d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10e6e2-e50c-4c42-a9e2-7ad47f782dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "# Create a synthetic checkerboard image\n",
    "def create_checkerboard(size=(200, 200), num_checks=10):\n",
    "    # Create a checkerboard pattern\n",
    "    x = np.linspace(0, num_checks, size[1])\n",
    "    y = np.linspace(0, num_checks, size[0])\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    checkerboard = ((np.floor(X) + np.floor(Y)) % 2)\n",
    "    return checkerboard\n",
    "\n",
    "# Apply barrel distortion to the image\n",
    "def apply_barrel_distortion(image, k1=0.3):\n",
    "    # Normalize image coordinates to the range [-1, 1]\n",
    "    h, w = image.shape\n",
    "    x, y = np.meshgrid(np.linspace(-1, 1, w), np.linspace(-1, 1, h))\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    \n",
    "    # Apply barrel distortion\n",
    "    x_distorted = x * (1 + k1 * r**2)\n",
    "    y_distorted = y * (1 + k1 * r**2)\n",
    "    \n",
    "    # Map the distorted coordinates back to image coordinates\n",
    "    x_distorted = ((x_distorted + 1) / 2) * (w - 1)\n",
    "    y_distorted = ((y_distorted + 1) / 2) * (h - 1)\n",
    "    \n",
    "    # Use map_coordinates to interpolate the image at the distorted coordinates\n",
    "    distorted_image = map_coordinates(image, [y_distorted.flatten(), x_distorted.flatten()], order=1).reshape(h, w)\n",
    "    return distorted_image, x_distorted, y_distorted\n",
    "\n",
    "# Use RBF interpolation to correct the distortion\n",
    "def correct_distortion_rbf(distorted_image, x_distorted, y_distorted):\n",
    "    h, w = distorted_image.shape\n",
    "    # Generate the original grid coordinates\n",
    "    x_original, y_original = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    \n",
    "    # Flatten the arrays for processing\n",
    "    x_original_flat = x_original.flatten()\n",
    "    y_original_flat = y_original.flatten()\n",
    "    x_distorted_flat = x_distorted.flatten()\n",
    "    y_distorted_flat = y_distorted.flatten()\n",
    "    \n",
    "    # Use a subset of points for the RBF due to computational constraints\n",
    "    # Select every Nth point to reduce the number of points\n",
    "    N = 5  # Adjust N for a balance between performance and accuracy\n",
    "    indices = np.arange(0, len(x_original_flat), N)\n",
    "    \n",
    "    # Prepare the data for RBF\n",
    "    points_distorted = np.vstack((x_distorted_flat[indices], y_distorted_flat[indices]))\n",
    "    points_original = np.vstack((x_original_flat[indices], y_original_flat[indices]))\n",
    "    points_x = np.vstack((x_original_flat, y_original_flat)).T\n",
    "    points_original1=points_original.T\n",
    "    points_distorted1=points_distorted.T\n",
    "    # Create RBF interpolators for x and y mappings\n",
    "    p_ref=np.array([0,0])    \n",
    "    no_evaluation_points=x_original_flat.shape[0]\n",
    "    distance =cdist(points_x,points_distorted1)\n",
    "    closest = np.argpartition(distance, 10, axis=1)\n",
    "    scaled_training_set_flat = []\n",
    "    eps_final_hardy=np.zeros((no_evaluation_points,1))\n",
    "    eps_final_franke=np.zeros((no_evaluation_points,1))\n",
    "    eps_final_mfranke=np.zeros((no_evaluation_points,1))\n",
    "    eps_final_rippa=np.zeros((no_evaluation_points,2))\n",
    "    \n",
    "    x_coords = []\n",
    "    f=[]\n",
    "    x_corrected_flat=np.zeros((5,no_evaluation_points))\n",
    "    y_corrected_flat=np.zeros((5,no_evaluation_points))\n",
    "    for i in range(no_evaluation_points):\n",
    "        x_local=np.zeros((10,2))\n",
    "        fpart=np.zeros((10+1,2))\n",
    "        for j in range(10):\n",
    "            x_local[j]=points_distorted1[closest[i][j]]\n",
    "            fpart[j]=points_original1[closest[i][j]]\n",
    "        x_local = sorted( x_local, key = lambda x: np.linalg.norm(x - p_ref ) )\n",
    "        x_local = np.reshape(x_local, (10,2)) \n",
    "        x_coords.append(x_local)\n",
    "        f.append(fpart)\n",
    "        x_axis=x_local.reshape(10,2)\n",
    "        # Hardy approach\n",
    "        nearest_distances = find_nearest_neighbors(x_axis)\n",
    "        d=np.sum(nearest_distances)/n        \n",
    "        eps_final_hardy[i]=1/(0.815*d)\n",
    "\n",
    "        # Franke approach\n",
    "        x_axis_list=x_axis.tolist()        \n",
    "        circle = find_min_circle(x_axis_list)\n",
    "        eps_final_franke[i]=0.8*(10**(1/2))/(2 * circle[2])\n",
    "\n",
    "        # Modified Franke approach\n",
    "        eps_final_mfranke[i]=0.8*(10**(1/4))/(2 * circle[2])\n",
    "\n",
    "        # Rippa approach       \n",
    "        rhs_rippa = fpart[:10][:,0]\n",
    "        eps_v = [0.001, 0.002, 0.005, 0.0075, 0.01, 0.02, 0.05, 0.075, 0.1, 0.2, 0.5, 0.75, 1.0,\\\n",
    "                 2.0, 5.0, 7.5, 10.0, 20.0, 50.0, 75.0, 100.0, 200.0, 500.0, 1000.0] # from python library\n",
    "        best_eps = 0\n",
    "        old_error = np.inf        \n",
    "        for eps in eps_v:\n",
    "            error_r = rippa_cv(eps, x_axis, rhs_rippa)\n",
    "            if error_r < old_error:\n",
    "               best_eps = eps\n",
    "               old_error = error_r\n",
    "        eps_final_rippa[i,0]=best_eps\n",
    "\n",
    "        rhs_rippa = fpart[:10][:,1]\n",
    "        eps_v = [0.001, 0.002, 0.005, 0.0075, 0.01, 0.02, 0.05, 0.075, 0.1, 0.2, 0.5, 0.75, 1.0,\\\n",
    "                 2.0, 5.0, 7.5, 10.0, 20.0, 50.0, 75.0, 100.0, 200.0, 500.0, 1000.0] # from python library\n",
    "        best_eps = 0\n",
    "        old_error = np.inf        \n",
    "        for eps in eps_v:\n",
    "            error_r = rippa_cv(eps, x_axis, rhs_rippa)\n",
    "            if error_r < old_error:\n",
    "               best_eps = eps\n",
    "               old_error = error_r\n",
    "        eps_final_rippa[i,1]=best_eps\n",
    "        \n",
    "        # NN approach\n",
    "        xxx=generate_distance_from_coordinates(x_axis)               \n",
    "        training_set_distances_flatten = upper_half(xxx)\n",
    "        scaled_training_set_flat.append(training_set_distances_flatten)\n",
    "\n",
    "    scaled_training_set_tensor = torch.tensor(scaled_training_set_flat,dtype=torch.float)\n",
    "    scaled_training_set_tensor.reshape((no_evaluation_points,int(10*10/2-10/2)))\n",
    "        \n",
    "    eps_final= model(scaled_training_set_tensor)\n",
    "    eps_final_optimisation = eps_final.detach().numpy()\n",
    "\n",
    "    for j in range(no_evaluation_points):\n",
    "        for count,eps in enumerate([eps_final_rippa[j],eps_final_hardy[j][0],eps_final_franke[j][0],eps_final_mfranke[j][0],eps_final_optimisation[j][0]]):\n",
    "\n",
    "            if count==0:\n",
    "                Lx =  get_int_matrix(x_coords[j],eps[0])\n",
    "                Ly =  get_int_matrix(x_coords[j],eps[1])\n",
    "                fx=f[j][:,0]\n",
    "                fy=f[j][:,1]\n",
    "\n",
    "                wx=np.linalg.solve(Lx, fx) \n",
    "                wy=np.linalg.solve(Ly, fy) \n",
    "    \n",
    "                sx=np.zeros((1,10+1))\n",
    "                sy=np.zeros((1,10+1))\n",
    "                for i in range(10):      \n",
    "                    sx[0,i] = phi(eps[0],points_x[j] , x_coords[j][i])\n",
    "                    sy[0,i] = phi(eps[1],points_x[j] , x_coords[j][i])\n",
    "                sx[0,-1]=1.0 \n",
    "                sy[0,-1]=1.0 \n",
    "   \n",
    "                x_corrected_flat[count][j]=np.matmul(sx,wx)        \n",
    "                y_corrected_flat[count][j]=np.matmul(sy,wy)\n",
    "\n",
    "            else:\n",
    "                L =  get_int_matrix(x_coords[j],eps)\n",
    "                \n",
    "                fx=f[j][:,0]\n",
    "                fy=f[j][:,1]\n",
    "\n",
    "                wx=np.linalg.solve(L, fx) \n",
    "                wy=np.linalg.solve(L, fy) \n",
    "    \n",
    "                s=np.zeros((1,10+1))\n",
    "                for i in range(10):      \n",
    "                    s[0,i] = phi(eps,points_x[j] , x_coords[j][i])\n",
    "                s[0,-1]=1.0        \n",
    "   \n",
    "                x_corrected_flat[count][j]=np.matmul(s,wx)        \n",
    "                y_corrected_flat[count][j]=np.matmul(s,wy)\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    corrected_image=[]\n",
    "    for count in range(5):\n",
    "        # Ensure the coordinates are within image bounds\n",
    "        x_corrected_flat[count] = np.clip(x_corrected_flat[count], 0, w - 1)\n",
    "        y_corrected_flat[count] = np.clip(y_corrected_flat[count], 0, h - 1)\n",
    "    \n",
    "        # Use map_coordinates to get the corrected image\n",
    "        corrected_image.append(map_coordinates(distorted_image, [y_corrected_flat[count], x_corrected_flat[count]], order=1).reshape(h, w))\n",
    "    return corrected_image\n",
    "\n",
    "# Visualize the images\n",
    "def display_images(corrected_image,file_name):\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(corrected_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'corrected_'+file_name,bbox_inches='tight', dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "original_image = create_checkerboard()  # Create a synthetic checkerboard image\n",
    "distorted_image, x_distorted, y_distorted = apply_barrel_distortion(original_image)  # Apply barrel distortion\n",
    "corrected_image = correct_distortion_rbf(distorted_image, x_distorted, y_distorted)  # Correct the distortion\n",
    "\n",
    "fig1 = plt.figure(figsize=(10, 6))\n",
    "plt.imshow(original_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'original',bbox_inches='tight', dpi=150)\n",
    "plt.close(fig1)\n",
    "\n",
    "fig2 = plt.figure(figsize=(10, 6))\n",
    "plt.imshow(distorted_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'distorted',bbox_inches='tight', dpi=150)\n",
    "plt.close(fig2)\n",
    "\n",
    "strategies=['Rippa','Hardy','Franke','Modified Franke', 'NN']\n",
    "\n",
    "mse=[0 for i in range(5)]\n",
    "psnr=[0 for i in range(5)]\n",
    "\n",
    "for count in range(5):\n",
    "    print('Shape parameter strategy:',strategies[count])\n",
    "    display_images(corrected_image[count],strategies[count])  # Display the images\n",
    "    mse[count] = np.mean((original_image - corrected_image[count]) ** 2)\n",
    "    psnr[count]=20*np.log10(np.max(original_image)/np.sqrt(mse[count]))\n",
    "\n",
    "print('mse',mse)\n",
    "print('psnr',psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac53ab5-0ee3-4ff8-be7c-1fd94ee84c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
