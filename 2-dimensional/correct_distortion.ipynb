{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1393b3c3-5a2e-49c4-ae37-e1f0552f24c8",
   "metadata": {},
   "source": [
    "# Image distortion notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5654df-ec26-484b-943c-7cb8c82828cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import math\n",
    "from math import exp\n",
    "from random import seed\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "\n",
    "import sys\n",
    "sys.path.append('../common/')\n",
    "from utils import *\n",
    "from optimisation import *\n",
    "from loo_cv import *\n",
    "from image_commons import *\n",
    "from scipy.ndimage import map_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c86e483-5be7-4642-add9-8f75173ae1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=0\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c309a446-b2c2-4afa-8d17-31b66dc8483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # layers, activations and more\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "from torch.jit import script, trace       # hybrid frontend decorator and tracing jit\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013178c9-b1b1-4a37-af19-afc98392be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,N=10):\n",
    "            super(Net, self).__init__()\n",
    "            \n",
    "            nInputs = int(N*N/2-N/2)\n",
    "            \n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(in_features=nInputs, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=32, out_features=16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=16, out_features=1)\n",
    "            )\n",
    "            # map to positive\n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f5cfa-054b-4a9e-8e7c-a1229c2a92b8",
   "metadata": {},
   "source": [
    "# Generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aea2d2e9-4101-4f7e-9d5e-befd1948a6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_half(A):\n",
    "    n = A.shape[0]\n",
    "    return 1/A[np.triu_indices(n, k = 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05a2588b-1c21-43a5-b39b-77fe22587c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=45, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=16, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# network to be tested:\n",
    "n=10\n",
    "path =   '../network/results_sorted_1d_2d/best_model.pt'\n",
    "model=Net()\n",
    "model.load_state_dict(torch.load(path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c0eb30-f6ae-4c30-b284-7e909292b033",
   "metadata": {},
   "source": [
    "# Distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee10e6e2-e50c-4c42-a9e2-7ad47f782dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply barrel distortion to the image\n",
    "def apply_barrel_distortion(image, k1=0.3):\n",
    "    # Normalize image coordinates to the range [-1, 1]\n",
    "    h, w = image.shape\n",
    "    x, y = np.meshgrid(np.linspace(-1, 1, w), np.linspace(-1, 1, h))\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    \n",
    "    # Apply barrel distortion\n",
    "    x_distorted = x * (1 + k1 * r**2)\n",
    "    y_distorted = y * (1 + k1 * r**2)\n",
    "    \n",
    "    # Map the distorted coordinates back to image coordinates\n",
    "    x_distorted = ((x_distorted + 1) / 2) * (w - 1)\n",
    "    y_distorted = ((y_distorted + 1) / 2) * (h - 1)\n",
    "    \n",
    "    # Use map_coordinates to interpolate the image at the distorted coordinates\n",
    "    distorted_image = map_coordinates(image, [y_distorted.flatten(), x_distorted.flatten()], order=1).reshape(h, w)\n",
    "    return distorted_image, x_distorted, y_distorted\n",
    "\n",
    "# Use RBF interpolation to correct the distortion\n",
    "def correct_distortion_rbf(distorted_image, x_distorted, y_distorted):\n",
    "    h, w = distorted_image.shape\n",
    "    # Generate the original grid coordinates\n",
    "    x_original, y_original = np.meshgrid(np.arange(w), np.arange(h))\n",
    "    \n",
    "    # Flatten the arrays for processing\n",
    "    x_original_flat = x_original.flatten()\n",
    "    y_original_flat = y_original.flatten()\n",
    "    x_distorted_flat = x_distorted.flatten()\n",
    "    y_distorted_flat = y_distorted.flatten()\n",
    "    \n",
    "    # Use a subset of points for the RBF due to computational constraints\n",
    "    # Select every Nth point to reduce the number of points\n",
    "    N = 5  # Adjust N for a balance between performance and accuracy\n",
    "    indices = np.arange(0, len(x_original_flat), N)\n",
    "    \n",
    "    # Prepare the data for RBF\n",
    "    points_distorted = np.vstack((x_distorted_flat[indices], y_distorted_flat[indices]))\n",
    "    points_original = np.vstack((x_original_flat[indices], y_original_flat[indices]))\n",
    "    points_x = np.vstack((x_original_flat, y_original_flat)).T\n",
    "    points_original1=points_original.T\n",
    "    points_distorted1=points_distorted.T\n",
    "    # Create RBF interpolators for x and y mappings\n",
    "    p_ref=np.array([0,0])    \n",
    "    no_evaluation_points=x_original_flat.shape[0]\n",
    "    distance =cdist(points_x,points_distorted1)\n",
    "    closest = np.argpartition(distance, 10, axis=1)\n",
    "    scaled_training_set_flat = []\n",
    "    eps_final_hardy=np.zeros((no_evaluation_points,1))\n",
    "    eps_final_franke=np.zeros((no_evaluation_points,1))\n",
    "    eps_final_mfranke=np.zeros((no_evaluation_points,1))\n",
    "    eps_final_rippa=np.zeros((no_evaluation_points,2))\n",
    "    eps_final_mle=np.zeros((no_evaluation_points,2))\n",
    "    \n",
    "    x_coords = []\n",
    "    f=[]\n",
    "    x_corrected_flat=np.zeros((6,no_evaluation_points))\n",
    "    y_corrected_flat=np.zeros((6,no_evaluation_points))\n",
    "    for i in range(no_evaluation_points):\n",
    "        x_local=np.zeros((10,2))\n",
    "        fpart=np.zeros((10+1,2))\n",
    "        for j in range(10):\n",
    "            x_local[j]=points_distorted1[closest[i][j]]\n",
    "            fpart[j]=points_original1[closest[i][j]]\n",
    "        x_local = sorted( x_local, key = lambda x: np.linalg.norm(x - p_ref ) )\n",
    "        x_local = np.reshape(x_local, (10,2)) \n",
    "        x_coords.append(x_local)\n",
    "        f.append(fpart)\n",
    "        x_axis=x_local.reshape(10,2)\n",
    "        # Hardy approach\n",
    "        nearest_distances = find_nearest_neighbors(x_axis)\n",
    "        d=np.sum(nearest_distances)/n        \n",
    "        eps_final_hardy[i]=1/(0.815*d)\n",
    "\n",
    "        # Franke approach\n",
    "        x_axis_list=x_axis.tolist()        \n",
    "        circle = find_min_circle(x_axis_list)\n",
    "        eps_final_franke[i]=0.8*(10**(1/2))/(2 * circle[2])\n",
    "\n",
    "        # Modified Franke approach\n",
    "        eps_final_mfranke[i]=0.8*(10**(1/4))/(2 * circle[2])\n",
    "\n",
    "        # Rippa approach       \n",
    "        eps_v = [0.001, 0.002, 0.005, 0.0075, 0.01, 0.02, 0.05, 0.075, \\\n",
    "                 0.1, 0.2, 0.5, 0.75,1,2, 5, 7.5, 10, 20.0, 50, 75, 100, 200, 500, 1000]     \n",
    "        # \n",
    "        ## x-axis\n",
    "        rhs_rippa = fpart[:10][:,0]\n",
    "        best_eps = 0\n",
    "        old_error = np.inf        \n",
    "        for eps in eps_v:\n",
    "            error_r = rippa_cv(eps, x_axis, rhs_rippa)\n",
    "            if error_r < old_error:\n",
    "               best_eps = eps\n",
    "               old_error = error_r\n",
    "        eps_final_rippa[i,0]=best_eps\n",
    "\n",
    "        # y-axis\n",
    "        rhs_rippa = fpart[:10][:,1]\n",
    "        best_eps = 0\n",
    "        old_error = np.inf        \n",
    "        for eps in eps_v:\n",
    "            error_r = rippa_cv(eps, x_axis, rhs_rippa)\n",
    "            if error_r < old_error:\n",
    "               best_eps = eps\n",
    "               old_error = error_r\n",
    "        eps_final_rippa[i,1]=best_eps\n",
    "\n",
    "        # MLE approach\n",
    "        rhs_rippa = fpart[:10][:,0]\n",
    "        best_eps = 1.0\n",
    "        old_error = np.inf        \n",
    "        for eps in eps_v:\n",
    "            error_r = mle_cv(eps, x_axis, rhs_rippa)\n",
    "            if error_r < old_error:\n",
    "               best_eps = eps\n",
    "               old_error = error_r\n",
    "        eps_final_mle[i,0]=best_eps\n",
    "        # y-axis\n",
    "        rhs_rippa = fpart[:10][:,1]\n",
    "        best_eps = 1.0\n",
    "        old_error = np.inf        \n",
    "        for eps in eps_v:\n",
    "            error_r = mle_cv(eps, x_axis, rhs_rippa)\n",
    "            if error_r < old_error:\n",
    "               best_eps = eps\n",
    "               old_error = error_r\n",
    "        eps_final_mle[i,1]=best_eps\n",
    "        \n",
    "        # NN approach\n",
    "        xxx=generate_distance_from_coordinates(x_axis)               \n",
    "        training_set_distances_flatten = upper_half(xxx)\n",
    "        scaled_training_set_flat.append(training_set_distances_flatten)\n",
    "        if i%1000==0:\n",
    "            print(i)\n",
    "        \n",
    "\n",
    "    scaled_training_set_tensor = torch.tensor(scaled_training_set_flat,dtype=torch.float)\n",
    "    scaled_training_set_tensor.reshape((no_evaluation_points,int(10*10/2-10/2)))\n",
    "        \n",
    "    eps_final= model(scaled_training_set_tensor)\n",
    "    eps_final_optimisation = eps_final.detach().numpy()\n",
    "\n",
    "    for j in range(no_evaluation_points):\n",
    "        for count,eps in enumerate([eps_final_mle[j],eps_final_rippa[j],eps_final_hardy[j][0]\\\n",
    "                                    ,eps_final_franke[j][0],\\\n",
    "                                    eps_final_mfranke[j][0],eps_final_optimisation[j][0]]):\n",
    "\n",
    "            if count==0 or count==1: #choose ripa or mle\n",
    "                Lx =  get_int_matrix(x_coords[j],eps[0])\n",
    "                Ly =  get_int_matrix(x_coords[j],eps[1])\n",
    "                fx=f[j][:,0]\n",
    "                fy=f[j][:,1]\n",
    "\n",
    "                wx=np.linalg.solve(Lx, fx) \n",
    "                wy=np.linalg.solve(Ly, fy) \n",
    "    \n",
    "                sx=np.zeros((1,10+1))\n",
    "                sy=np.zeros((1,10+1))\n",
    "                for i in range(10):      \n",
    "                    sx[0,i] = phi(eps[0],points_x[j] , x_coords[j][i])\n",
    "                    sy[0,i] = phi(eps[1],points_x[j] , x_coords[j][i])\n",
    "                sx[0,-1]=1.0 \n",
    "                sy[0,-1]=1.0 \n",
    "   \n",
    "                x_corrected_flat[count][j]=np.matmul(sx,wx)        \n",
    "                y_corrected_flat[count][j]=np.matmul(sy,wy)\n",
    "\n",
    "            else:\n",
    "                L =  get_int_matrix(x_coords[j],eps)\n",
    "                \n",
    "                fx=f[j][:,0]\n",
    "                fy=f[j][:,1]\n",
    "\n",
    "                wx=np.linalg.solve(L, fx) \n",
    "                wy=np.linalg.solve(L, fy) \n",
    "    \n",
    "                s=np.zeros((1,10+1))\n",
    "                for i in range(10):      \n",
    "                    s[0,i] = phi(eps,points_x[j] , x_coords[j][i])\n",
    "                s[0,-1]=1.0        \n",
    "   \n",
    "                x_corrected_flat[count][j]=np.matmul(s,wx)        \n",
    "                y_corrected_flat[count][j]=np.matmul(s,wy)\n",
    "\n",
    "    corrected_image=[]\n",
    "    for count in range(6):\n",
    "        # Ensure the coordinates are within image bounds\n",
    "        x_corrected_flat[count] = np.clip(x_corrected_flat[count], 0, w - 1)\n",
    "        y_corrected_flat[count] = np.clip(y_corrected_flat[count], 0, h - 1)\n",
    "    \n",
    "        # Use map_coordinates to get the corrected image\n",
    "        corrected_image.append(map_coordinates(distorted_image, [y_corrected_flat[count], x_corrected_flat[count]], order=1).reshape(h, w))\n",
    "    return corrected_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ea4613-be0f-42e5-afba-bce967f00075",
   "metadata": {},
   "source": [
    "# Checkerboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41044840-da7f-4fb1-beee-945f777d9951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PAS2708/hanveiga1/new_rbf/RBF-shape-parameter-NN/2-dimensional/../common/loo_cv.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  term1 = np.log(np.dot(rhs2,w)+1e-16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "original_image = create_checkerboard(size=(200, 200))  # Create a synthetic checkerboard image\n",
    "distorted_image, x_distorted, y_distorted = apply_barrel_distortion(original_image)  # Apply barrel distortion\n",
    "corrected_image = correct_distortion_rbf(distorted_image, x_distorted, y_distorted)  # Correct the distortion\n",
    "\n",
    "fig1 = plt.figure(figsize=(10, 6))\n",
    "plt.imshow(original_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'original_checkerboard',bbox_inches='tight', dpi=150)\n",
    "plt.close(fig1)\n",
    "\n",
    "fig2 = plt.figure(figsize=(10, 6))\n",
    "plt.imshow(distorted_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'distorted_checkerboard',bbox_inches='tight', dpi=150)\n",
    "plt.close(fig2)\n",
    "\n",
    "strategies=['MLE','Rippa','Hardy','Franke','Modified Franke', 'NN']\n",
    "\n",
    "mse=[0 for i in range(6)]\n",
    "psnr=[0 for i in range(6)]\n",
    "\n",
    "for count in range(6):\n",
    "    print('Shape parameter strategy:',strategies[count])\n",
    "    display_images(corrected_image[count],strategies[count]+'_distortion_checkerboard')  # Display the images\n",
    "    mse[count] = np.mean((original_image - corrected_image[count]) ** 2)\n",
    "    psnr[count]=20*np.log10(np.max(original_image)/np.sqrt(mse[count]))\n",
    "\n",
    "print('mse',mse)\n",
    "print('psnr',psnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0667f6f-55fe-4491-b792-c0429d645185",
   "metadata": {},
   "source": [
    "# Flowers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21d78735-c740-41bb-9fdf-f062a1c954c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PAS2708/hanveiga1/RBF-shape-parameter-NN/2-dimensional/image/../../common/loo_cv.py:51: RuntimeWarning: invalid value encountered in log\n",
      "  term2 = np.log(np.linalg.det(M)+1e-16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/PAS2708/hanveiga1/RBF-shape-parameter-NN/2-dimensional/image/../../common/loo_cv.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  term1 = np.log(np.dot(rhs2,w)+1e-16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/slurmtmp.672334/ipykernel_3483328/3065281354.py:150: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  scaled_training_set_tensor = torch.tensor(scaled_training_set_flat,dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.2963371]\n",
      " [2.2955346]\n",
      " [2.2942011]\n",
      " ...\n",
      " [2.2999425]\n",
      " [2.2976205]\n",
      " [2.2967668]] [[0.1 0.1]\n",
      " [0.1 0.1]\n",
      " [0.1 0.1]\n",
      " ...\n",
      " [0.1 0.1]\n",
      " [0.1 0.1]\n",
      " [0.1 0.1]]\n",
      "Shape parameter strategy: MLE\n",
      "Shape parameter strategy: Rippa\n",
      "Shape parameter strategy: Hardy\n",
      "Shape parameter strategy: Franke\n",
      "Shape parameter strategy: Modified Franke\n",
      "Shape parameter strategy: NN\n",
      "mse [0.04829213969189625, 0.022922648401014437, 0.0064938067279571, 0.010202850320608513, 0.022342162797972482, 0.004253296261518399]\n",
      "psnr [12.919465525637822, 16.155582077553262, 21.633236419997463, 19.67101485337724, 16.266977887748446, 23.47097366421899]\n"
     ]
    }
   ],
   "source": [
    "path = 'flower.png'\n",
    "original_image = load_image(path)\n",
    "distorted_image, x_distorted, y_distorted = apply_barrel_distortion(original_image)  # Apply barrel distortion\n",
    "corrected_image = correct_distortion_rbf(distorted_image, x_distorted, y_distorted)  # Correct the distortion\n",
    "\n",
    "fig1 = plt.figure(figsize=(10, 6))\n",
    "plt.imshow(original_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'original_flower',bbox_inches='tight', dpi=150)\n",
    "plt.close(fig1)\n",
    "\n",
    "fig2 = plt.figure(figsize=(10, 6))\n",
    "plt.imshow(distorted_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig(f'distorted_flower',bbox_inches='tight', dpi=150)\n",
    "plt.close(fig2)\n",
    "\n",
    "strategies=['MLE','Rippa','Hardy','Franke','Modified Franke', 'NN']\n",
    "\n",
    "mse=[0 for i in range(6)]\n",
    "psnr=[0 for i in range(6)]\n",
    "\n",
    "for count in range(6):\n",
    "    print('Shape parameter strategy:',strategies[count])\n",
    "    display_images(corrected_image[count],strategies[count]+\"_distortion_flower\")  # Display the images\n",
    "    mse[count] = np.mean((original_image - corrected_image[count]) ** 2)\n",
    "    psnr[count]=20*np.log10(np.max(original_image)/np.sqrt(mse[count]))\n",
    "\n",
    "print('mse',mse)\n",
    "print('psnr',psnr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL2",
   "language": "python",
   "name": "mpg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
