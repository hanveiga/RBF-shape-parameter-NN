{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5654df-ec26-484b-943c-7cb8c82828cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import math\n",
    "from math import exp\n",
    "from random import seed\n",
    "from random import random\n",
    "from random import sample\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle \n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../common/')\n",
    "sys.path.append('../dataset/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c86e483-5be7-4642-add9-8f75173ae1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_seed=0\n",
    "torch.manual_seed(torch_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbf91a8-b6fe-4946-a89c-bfaa00a4d3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81d21c6-07f4-4127-8851-1675d6fa5797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make function to load data\n",
    "# Assuming we get a np.array with nData x 3, first column is x axis, second is y axis, third is epsilon\n",
    "path1 = '../dataset/sort_1d_11_11.5.pkl'\n",
    "data1 = pickle.load(open(path1,'rb'))\n",
    "nData1 = len(data1)\n",
    "\n",
    "\n",
    "for i in range(nData1):\n",
    "    A_points=data1[i][0].reshape(10,2)\n",
    "    coordinates.append(A_points)\n",
    "    y.append(np.abs(data1[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238b7f8-10b3-4e0b-b3ed-a21e125bedf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = '../dataset/sort_2d_11_11.5.pkl'\n",
    "data2 = pickle.load(open(path2,'rb'))\n",
    "nData2 = len(data2)\n",
    "\n",
    "for i in range(nData2):\n",
    "    A_points=data2[i][0].reshape(10,2)\n",
    "    coordinates.append(A_points)\n",
    "    y.append(np.abs(data2[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb869f-66fb-4d4c-9e3e-b0a80e1ffcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nData = nData1+nData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746cf29b-f50d-41f3-ac2b-fc68c678a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate distance matrix from coordinates\n",
    "\n",
    "def generate_distance_from_coordinates(x_axis):\n",
    "    B = np.zeros((x_axis.shape[0],x_axis.shape[0])) \n",
    "    for i in range(x_axis.shape[0]):\n",
    "        for j in range(x_axis.shape[0]):\n",
    "            B[i,j] = np.linalg.norm(x_axis[i]-x_axis[j])\n",
    "            \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309a446-b2c2-4afa-8d17-31b66dc8483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as autograd         # computation graph\n",
    "from torch import Tensor                  # tensor node in the computation graph\n",
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # layers, activations and more\n",
    "import torch.optim as optim               # optimizers e.g. gradient descent, ADAM, etc.\n",
    "from torch.jit import script, trace       # hybrid frontend decorator and tracing jit\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013178c9-b1b1-4a37-af19-afc98392be94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,N=10):\n",
    "            super(Net, self).__init__()\n",
    "            \n",
    "            nInputs = int(N*N/2-N/2)\n",
    "            \n",
    "            self.linear_relu_stack = nn.Sequential(\n",
    "                nn.Linear(in_features=nInputs, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=64, out_features=32),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=32, out_features=16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features=16, out_features=1)\n",
    "            )\n",
    "            # map to positive\n",
    "            \n",
    "            \n",
    "    def forward(self, x):\n",
    "            logits = self.linear_relu_stack(x)\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ea501-dbce-483d-8d20-1c2af88107af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_to_tensor(array):\n",
    "    # shares the same memory -- could be problematic?\n",
    "    return torch.tensor(array,dtype=torch.float)\n",
    "    \n",
    "def tensor_to_np(tensor):\n",
    "    return tensor.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006db932-b43a-400e-9182-592b05910d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, tolerance=5, min_delta=0):\n",
    "\n",
    "        self.tolerance = tolerance\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, train_loss, validation_loss):\n",
    "        if (validation_loss - train_loss) > self.min_delta:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.tolerance:  \n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f977cb-0d0d-4e5c-aca2-2b298529f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(nData):\n",
    "    X.append(generate_distance_from_coordinates(coordinates[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004b9e6a-61a8-4314-b8b0-b5d11d3dea01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_upperhalf = []\n",
    "def upper_half(A):\n",
    "    n = A.shape[0]\n",
    "    return 1/A[np.triu_indices(n, k = 1)]\n",
    "\n",
    "for i in range(len(X)):\n",
    "    X_upperhalf.append(upper_half(X[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2474a1d-f96d-4257-a976-54b60dd83d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler,MinMaxScaler\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "X = np.array(X_upperhalf)\n",
    "y = np.array(y)\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "N= 10\n",
    "training_set_distances_flatten = X.reshape((nData,int(N*N/2-N/2)))\n",
    "scaled_training_set_flat = training_set_distances_flatten \n",
    "scaled_training_set_tensor = torch.tensor(scaled_training_set_flat,dtype=torch.float)\n",
    "\n",
    "scaled_training_labels = y\n",
    "scaled_training_labels_tensor = torch.tensor(scaled_training_labels,dtype=torch.float)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset( scaled_training_set_tensor, scaled_training_labels_tensor)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset,[int(0.9*nData),nData-int(0.9*nData)])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390c5eb-716e-49ef-a2be-2a3a3382b683",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'results_sorted_1d_2d/'\n",
    "\n",
    "# if folder does not exist, create folder\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8935501a-0ff3-4476-9aba-dc70c0b3403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00001\n",
    "weight_decay = 0.00005\n",
    "step_size = 10# 5\n",
    "epochs = 3000\n",
    "\n",
    "f = open(model_path+\"specs.txt\", \"a\")\n",
    "f.write(f\"data_paths: {path1},  {path2} \\n\")\n",
    "f.write(f\"learning rate: {lr} \\n\")\n",
    "f.write(f\"weight decay: {weight_decay} \\n\")\n",
    "f.write(f\"step size: {step_size} \\n\")\n",
    "f.write(f\"epochs: {epochs} \\n\")\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85d9f0-d0aa-4db1-ae65-4064e5035132",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr ,weight_decay=weight_decay)#lr=0.00001\n",
    "scheduler = StepLR(optimizer, step_size=step_size, gamma=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd9cac-7c6e-4e71-ab52-e35625052070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loss=[]\n",
    "validation_loss=[]\n",
    "lowest_loss = 1000.\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "early_stopping_counter = 0\n",
    "early_stopping_patience = 200\n",
    "best_val_loss = float(\"inf\") \n",
    "\n",
    "for epoch in range(epochs):  #1000# loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, ytrue = data     \n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        #print('outputs',outputs.shape)\n",
    "        #print('ytrue',ytrue.shape)\n",
    "        loss = loss_fn(outputs,ytrue)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "             \n",
    "    running_loss = running_loss/(i+1)\n",
    "    scheduler.step()\n",
    "    train_loss.append(running_loss)\n",
    "    #avg_vloss = 0\n",
    "        # validation \n",
    "    with torch.no_grad(): \n",
    "        avg_vloss = 0.0\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            val_inputs, val_ytrue = data \n",
    "            val_outputs = model(val_inputs)\n",
    "            loss = loss_fn(val_outputs,val_ytrue)\n",
    "            avg_vloss += loss.item()\n",
    "        avg_vloss = avg_vloss/(i+1)\n",
    "        validation_loss.append(avg_vloss)\n",
    "        \n",
    "    if avg_vloss <= best_val_loss:\n",
    "        best_val_loss = avg_vloss\n",
    "        torch.save(model.state_dict(), model_path + 'best_model.pt')\n",
    "        \n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            print(\"Early stopping triggered. No improvement in validation accuracy for {} epochs.\".format(early_stopping_patience))\n",
    "            break\n",
    "    \n",
    "    print('Epoch {} LOSS train {} valid {}'.format(epoch,running_loss, avg_vloss))\n",
    "    \n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b938f3-8f74-46a1-9482-6384d555215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path + 'final_model.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RBF",
   "language": "python",
   "name": "rbf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
